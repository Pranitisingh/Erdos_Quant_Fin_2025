{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7d8b72",
   "metadata": {},
   "source": [
    "# Mini Project 2\n",
    "\n",
    "**2025 Introduction to Quantiative Methods in Finance**\n",
    "\n",
    "**The Erdös Institute**\n",
    "\n",
    "\n",
    "###  Hypothesis Testing of Standard Assumptions Theoretical Financial Mathematics\n",
    "\n",
    "In the theory of mathematical finance, it is common to assume the log returns of a stock/index are normally distributed.\n",
    "\n",
    "\n",
    "Investigate if the log returns of stocks or indexes of your choosing are normally distributed. Some suggestions for exploration include:\n",
    "\n",
    "    1) Test if there are period of times when the log-returns of a stock/index have evidence of normal distribution.\n",
    "    \n",
    "    2) Test if removing extremal return data creates a distribution with evidence of being normal.\n",
    "    \n",
    "    3) Create a personalized portfolio of stocks with historical log return data that is normally distributed.\n",
    "    \n",
    "    4) Test if the portfolio you created in the first mini-project has significant periods of time with evidence of normally distributed log returns.\n",
    "    \n",
    "    5) Gather x-number of historical stock data and just perform a normality test on their log return data to see if any of the stocks exhibit evidence of log returns that are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75df60cb-1e55-4869-b67d-cdbd2565e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "import datetime as dt\n",
    "import scipy.stats as stats\n",
    "sns.set_style('darkgrid')\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504cc3df-81fb-4127-8799-f70684951016",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing portfolios in the first mini-project for normality for significant periods of time.\n",
    "\n",
    "In first mini projects, we built 2 portfolios (of higher and lower risk) made up of stocks over 5 years:\n",
    "\n",
    "- **AAPL**: Apple Inc.  \n",
    "- **GM**: General Motors Company  \n",
    "- **NFLX**: Netflix, Inc.  \n",
    "- **F**: Ford Motor Company  \n",
    "- **ADBE**: Adobe Inc.  \n",
    "- **TSLA**: Tesla, Inc.\n",
    "\n",
    "We first find the portfolio return time series and then test for normality of log daily return distribution for time intervals of one year over 5 years. \n",
    "\n",
    "To assess whether the log returns are normally distributed, we perform D'Agostino and Pearson’s test for normality. The resulting p-value provides statistical evidence to evaluate the null hypothesis of normality. Specifically, if the p-value is less than 0.05, we reject the null hypothesis, indicating the log returns do not follow a normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4672a-6077-4980-ad57-68cfd8acc9c8",
   "metadata": {},
   "source": [
    "### Testing for lower risk portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "31aa9237-fe49-4f5a-a5ce-14f7700863be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3298376/559474746.py:8: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock = yf.download(tickers, start = start_date, end =end_date)\n",
      "[*********************100%***********************]  6 of 6 completed\n"
     ]
    }
   ],
   "source": [
    "#Uploading the portfolio data\n",
    "\n",
    "tickers = [\"AAPL\", \"GM\", \"NFLX\", \"F\", \"ADBE\", \"TSLA\"]\n",
    "\n",
    "start_date = dt.datetime.today()-dt.timedelta(days = 5*365)\n",
    "end_date = dt.datetime.today()\n",
    "\n",
    "stock = yf.download(tickers, start = start_date, end =end_date)\n",
    "\n",
    "#Find daily log returns for stocks\n",
    "daily_log_returns = np.log(stock['Close']/stock['Close'].shift(1))\n",
    "daily_log_returns = daily_log_returns.dropna()\n",
    "\n",
    "covariance_matrix = 252*((daily_log_returns).cov())\n",
    "\n",
    "# Number of assets i.e. stocks\n",
    "n_assets = len(tickers)\n",
    "\n",
    "# Define an initial guess for asset weights (we take equal weights)\n",
    "initial_weights = np.array([1/n_assets] * n_assets)\n",
    "\n",
    "# Define weight constraints\n",
    "constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights)-1}, #Sum of weights equals 1 \n",
    "               {'type': 'ineq', 'fun': lambda weights: min(weights)-.05}, #Allocate at least 5% of capital into each index in stock_symbols\n",
    "              {'type': 'ineq', 'fun': lambda weights: .30-max(weights)}) #Do not allocate more than 30% of capital into each index in stock_symbol\n",
    "\n",
    "# Objective function to minimize portfolio variance i.e. yearly volatility\n",
    "def portfolio_volatility(weights):\n",
    "    portfolio_std_dev = np.sqrt(np.dot(weights.T, np.dot(covariance_matrix, weights)))\n",
    "    return portfolio_std_dev\n",
    "\n",
    "# Run the optimization to find the optimal weights with constraints\n",
    "result = minimize(portfolio_volatility, initial_weights, constraints=constraints)\n",
    "\n",
    "# Optimal asset weights\n",
    "optimal_weights = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fb5713ca-4a18-48d0-8504-9726bdb12872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'Close' prices\n",
    "close = stock['Close']\n",
    "\n",
    "# Calculate daily returns (simple returns) for each stock\n",
    "daily_returns = close/close.iloc[0]\n",
    "daily_returns = daily_returns.dropna()\n",
    "\n",
    "# Calculate daily weighted portfolio returns\n",
    "daily_weighted_returns = daily_returns.dot(optimal_weights)\n",
    "\n",
    "# Calculate daily log returns of portfolio\n",
    "daily_log_weighted_returns = np.log(daily_weighted_returns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d9ac180e-42ae-4a21-96ff-3938e4acb048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical evidence for normal distribution from 2024-06-28 to 2025-06-28\n",
      "--------------------------------------------------------------------------------\n",
      "Statistical evidence for normal distribution from 2023-06-29 to 2024-06-28\n",
      "--------------------------------------------------------------------------------\n",
      "Statistical evidence for normal distribution from 2022-06-29 to 2023-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "No statistical evidence for normal distribution from 2021-06-29 to 2022-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "No statistical evidence for normal distribution from 2020-06-29 to 2021-06-29\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Perform normality test for each year over 5 years\n",
    "\n",
    "# Initialize list to store p-values and corresponding date ranges\n",
    "p_value_array = []\n",
    "\n",
    "for j in range(5):\n",
    "    # Define time window: from (j+1) years ago to j years ago\n",
    "    end_date = dt.datetime.today() - dt.timedelta(days=j*365)\n",
    "    start_date = dt.datetime.today() - dt.timedelta(days=(j+1)*365)\n",
    "    \n",
    "    # Filter log returns data for this yearly period\n",
    "    filtered_log_return_data = daily_log_weighted_returns.loc[start_date.strftime('%Y-%m-%d'):end_date.strftime('%Y-%m-%d')]\n",
    "    \n",
    "    # Perform normality test on filtered yearly log return data\n",
    "    p_value = stats.normaltest(filtered_log_return_data)[1]\n",
    "    \n",
    "    # Store (start_date to end_date) and associated p-value in list\n",
    "    p_value_array.append([start_date.strftime('%Y-%m-%d') + \" to \" + end_date.strftime('%Y-%m-%d'), p_value])\n",
    "\n",
    "# Iterate over stored p-values and print interpretation\n",
    "for period, p_val in p_value_array:\n",
    "    if p_val < 0.05:\n",
    "        print(f\"No statistical evidence for normal distribution from {period}\")\n",
    "    else:\n",
    "        print(f\"Statistical evidence for normal distribution from {period}\")\n",
    "    print('--' * 40)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c7c3a6-b263-4e7a-ac53-89011632abb5",
   "metadata": {},
   "source": [
    "### Testing for higher risk portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6cfd6aca-d220-4d49-a27f-f062a213f98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3298376/92788091.py:8: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock = yf.download(tickers, start = start_date, end =end_date)\n",
      "[*********************100%***********************]  6 of 6 completed\n"
     ]
    }
   ],
   "source": [
    "#Uploading the portfolio data\n",
    "\n",
    "tickers = [\"AAPL\", \"GM\", \"NFLX\", \"F\", \"ADBE\", \"TSLA\"]\n",
    "\n",
    "start_date = dt.datetime.today()-dt.timedelta(days = 5*365)\n",
    "end_date = dt.datetime.today()\n",
    "\n",
    "stock = yf.download(tickers, start = start_date, end =end_date)\n",
    "\n",
    "n_assets = len(tickers)\n",
    "\n",
    "\n",
    "# Portfolio with eqaul weights for each stock\n",
    "equal_weights = np.array([1/n_assets] * n_assets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "035cc00f-3058-4fc2-9254-116c452a4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'Close' prices\n",
    "close = stock['Close']\n",
    "\n",
    "# Calculate daily returns (simple returns) for each stock\n",
    "daily_returns = close/close.iloc[0]\n",
    "daily_returns = daily_returns.dropna()\n",
    "\n",
    "# Calculate daily weighted portfolio returns\n",
    "daily_weighted_returns = daily_returns.dot(equal_weights)\n",
    "\n",
    "# Calculate daily log returns of portfolio\n",
    "daily_log_weighted_returns = np.log(daily_weighted_returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1add787e-a667-4680-aa2f-7a99d152c38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No statistical evidence for normal distribution from 2024-06-28 to 2025-06-28\n",
      "--------------------------------------------------------------------------------\n",
      "Statistical evidence for normal distribution from 2023-06-29 to 2024-06-28\n",
      "--------------------------------------------------------------------------------\n",
      "Statistical evidence for normal distribution from 2022-06-29 to 2023-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "Statistical evidence for normal distribution from 2021-06-29 to 2022-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "No statistical evidence for normal distribution from 2020-06-29 to 2021-06-29\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Perform normality test for each year over 5 years\n",
    "\n",
    "# Initialize list to store p-values and corresponding date ranges\n",
    "p_value_array = []\n",
    "\n",
    "for j in range(5):\n",
    "    # Define time window: from (j+1) years ago to j years ago\n",
    "    end_date = dt.datetime.today() - dt.timedelta(days=j*365)\n",
    "    start_date = dt.datetime.today() - dt.timedelta(days=(j+1)*365)\n",
    "    \n",
    "    # Filter log returns data for this yearly period\n",
    "    filtered_log_return_data = daily_log_weighted_returns.loc[start_date.strftime('%Y-%m-%d'):end_date.strftime('%Y-%m-%d')]\n",
    "    \n",
    "    # Perform normality test on filtered yearly log return data\n",
    "    p_value = stats.normaltest(filtered_log_return_data)[1]\n",
    "    \n",
    "    # Store (start_date to end_date) and associated p-value in list\n",
    "    p_value_array.append([start_date.strftime('%Y-%m-%d') + \" to \" + end_date.strftime('%Y-%m-%d'), p_value])\n",
    "\n",
    "# Iterate over stored p-values and print interpretation\n",
    "for period, p_val in p_value_array:\n",
    "    if p_val < 0.05:\n",
    "        print(f\"No statistical evidence for normal distribution from {period}\")\n",
    "    else:\n",
    "        print(f\"Statistical evidence for normal distribution from {period}\")\n",
    "    print('--' * 40)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c7c9b5-d23e-4e6d-a51b-35e3f890797d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## Normality Test on Log Returns of Selected Stocks\n",
    "\n",
    "We analyze the log returns of the following stocks over the past five years of trading days:\n",
    "\n",
    "- Amazon.com, Inc. (AMZN)  \n",
    "- Microsoft Corporation (MSFT)  \n",
    "- Alphabet Inc. (GOOG)  \n",
    "- The Home Depot, Inc. (HD)  \n",
    "- General Motors Company (GM)  \n",
    "- Apple Inc. (AAPL)  \n",
    "- Intel Corporation (INTC)  \n",
    "- Adobe Inc. (ADBE)\n",
    "\n",
    "To assess whether the log returns are normally distributed, we perform D'Agostino and Pearson’s test for normality. The resulting p-value provides statistical evidence to evaluate the null hypothesis of normality. Specifically, if the p-value is less than 0.05, we reject the null hypothesis, indicating the log returns do not follow a normal distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dade323-ba47-48d6-8d28-358eec79c5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2499018/1379397510.py:8: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock = yf.download(tickers, start = start_date, end =end_date)\n",
      "[*********************100%***********************]  8 of 8 completed\n"
     ]
    }
   ],
   "source": [
    "# Upload stock x-number of stock data for 2 years\n",
    "tickers= ['AMZN', 'MSFT', 'GOOG', 'HD', 'GM','AAPL', 'INTC', 'ADBE']\n",
    "\n",
    "\n",
    "start_date = dt.datetime.today()-dt.timedelta(days = 5*365)\n",
    "end_date = dt.datetime.today()\n",
    "\n",
    "stock = yf.download(tickers, start = start_date, end =end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8d34a7-f597-402c-9993-67797e4e468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AMZN', 4.0703026631235075e-30], ['MSFT', 1.5612340539801503e-18], ['GOOG', 1.533550146188051e-22], ['HD', 3.672475568695469e-28], ['GM', 4.1746435261323195e-10], ['AAPL', 5.827347067355156e-34], ['INTC', 1.7886716279390967e-100], ['ADBE', 1.0938045110970739e-88]]\n"
     ]
    }
   ],
   "source": [
    "#Collect p-values of normality tests (D'Agostino and Pearson’s test)\n",
    "\n",
    "# Initialize list to store p-values\n",
    "p_value_array = []\n",
    "\n",
    "for i in tickers:\n",
    "    # Calculate daily returns and log returns for ticker i\n",
    "    stock_returns = stock['Close'] / stock['Close'].shift(1)\n",
    "    stock_log_returns = np.log(stock_returns.dropna())[i].values\n",
    "\n",
    "\n",
    "    # Perform normality test and extract p-value\n",
    "    p_value = stats.normaltest(stock_log_returns)[1]\n",
    "    \n",
    "    # Append ticker and p-value to list\n",
    "    p_value_array.append([i, p_value])\n",
    "\n",
    "# Print p-values for all stocks\n",
    "print(p_value_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9953ea35-3941-46b2-beae-53c6cc8ab292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for normality for stock, AMZN\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, MSFT\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, GOOG\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, HD\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, GM\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, AAPL\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, INTC\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, ADBE\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Print evidence/non-evidence of normality\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    print(f\"Test for normality for stock, {tickers[i]}\")\n",
    "    p_value = p_value_array[i]\n",
    "    if p_value[1]< 0.05:\n",
    "        print(\"→ Statistically significant evidence that the data is NOT normally distributed.\")\n",
    "    else:    \n",
    "       print(\"→ No statistically significant evidence against normality.\")\n",
    "    print('--'*40) \n",
    "    print('--'*40) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e49e1-f087-4a0c-998c-c48faab72adf",
   "metadata": {},
   "source": [
    "Thus, we see that the given stocks does not have evidence for normality of daily log-returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a43df8-3f77-481d-81ab-5566ba137eba",
   "metadata": {},
   "source": [
    "## Finding period of times where we have evidence for normal distribution\n",
    "\n",
    "Here, the 5 year stock data from previous sections is taken and then we perform D'Agostino and Pearson’s test for Normality of daily log returns on time periods of one year. Thus, for 5 years of data, we have 5 time intervals. For this test we compute p-value as statistical evidence. For p<0.05, the null hypothesis of normality is rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d1a038-9ce4-4f92-8799-6ca8ec85c77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2499018/2355453298.py:6: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock = yf.download(tickers, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  8 of 8 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tickers =  ['AMZN', 'MSFT', 'GOOG', 'HD', 'GM','AAPL', 'INTC', 'ADBE']\n",
    "start_date = dt.datetime.today() - dt.timedelta(days=5*365)\n",
    "end_date = dt.datetime.today()\n",
    "\n",
    "# Download data for all stocks\n",
    "stock = yf.download(tickers, start=start_date, end=end_date)\n",
    "\n",
    "# Extract 'Close' prices\n",
    "close = stock['Close']\n",
    "\n",
    "# Calculate daily simple returns for each stock\n",
    "daily_returns = close/close.iloc[0]\n",
    "daily_returns = daily_returns.dropna()\n",
    "\n",
    "# Calculate daily log returns for each stock\n",
    "daily_log_returns = np.log(daily_returns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36e27366-95bc-4378-bc18-0b3a0023dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for normality for stock, AMZN\n",
      "--------------------------------------------------------------------------------\n",
      "No statistically significant evidence for normal distribution for time period: 2024-06-28 to 2025-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2023-06-29 to 2024-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2022-06-29 to 2023-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2021-06-29 to 2022-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2020-06-29 to 2021-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, MSFT\n",
      "--------------------------------------------------------------------------------\n",
      "Statistically significant evidence for normal distribution for time period: 2024-06-28 to 2025-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2023-06-29 to 2024-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2022-06-29 to 2023-06-29\n",
      "Statistically significant evidence for normal distribution for time period: 2021-06-29 to 2022-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2020-06-29 to 2021-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, GOOG\n",
      "--------------------------------------------------------------------------------\n",
      "No statistically significant evidence for normal distribution for time period: 2024-06-28 to 2025-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2023-06-29 to 2024-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2022-06-29 to 2023-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2021-06-29 to 2022-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2020-06-29 to 2021-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, HD\n",
      "--------------------------------------------------------------------------------\n",
      "No statistically significant evidence for normal distribution for time period: 2024-06-28 to 2025-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2023-06-29 to 2024-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2022-06-29 to 2023-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2021-06-29 to 2022-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2020-06-29 to 2021-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, GM\n",
      "--------------------------------------------------------------------------------\n",
      "Statistically significant evidence for normal distribution for time period: 2024-06-28 to 2025-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2023-06-29 to 2024-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2022-06-29 to 2023-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2021-06-29 to 2022-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2020-06-29 to 2021-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, AAPL\n",
      "--------------------------------------------------------------------------------\n",
      "No statistically significant evidence for normal distribution for time period: 2024-06-28 to 2025-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2023-06-29 to 2024-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2022-06-29 to 2023-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2021-06-29 to 2022-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2020-06-29 to 2021-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, INTC\n",
      "--------------------------------------------------------------------------------\n",
      "No statistically significant evidence for normal distribution for time period: 2024-06-28 to 2025-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2023-06-29 to 2024-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2022-06-29 to 2023-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2021-06-29 to 2022-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2020-06-29 to 2021-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, ADBE\n",
      "--------------------------------------------------------------------------------\n",
      "No statistically significant evidence for normal distribution for time period: 2024-06-28 to 2025-06-28\n",
      "No statistically significant evidence for normal distribution for time period: 2023-06-29 to 2024-06-28\n",
      "Statistically significant evidence for normal distribution for time period: 2022-06-29 to 2023-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2021-06-29 to 2022-06-29\n",
      "No statistically significant evidence for normal distribution for time period: 2020-06-29 to 2021-06-29\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#printing results for test of normality after obtaining the p-values of different stocks\n",
    "\n",
    "# Initialize results list\n",
    "p_value_array = []\n",
    "\n",
    "# Perform normality test on each stock's yearly log returns\n",
    "for ticker in tickers:\n",
    "    for j in range(5):\n",
    "        # Define date range for year j\n",
    "        end_period = dt.datetime.today() - dt.timedelta(days=j*365)\n",
    "        start_period = dt.datetime.today() - dt.timedelta(days=(j+1)*365)\n",
    "        \n",
    "        # Filter log returns for the date range\n",
    "        filtered_log_returns = daily_log_returns[ticker].loc[start_period.strftime('%Y-%m-%d'):end_period.strftime('%Y-%m-%d')]\n",
    "        \n",
    "        # Perform normality test if there is sufficient data\n",
    "        if len(filtered_log_returns) > 0:\n",
    "            p_value = stats.normaltest(filtered_log_returns)[1]\n",
    "            p_value_array.append([ticker, start_period.strftime('%Y-%m-%d'), end_period.strftime('%Y-%m-%d'), p_value])\n",
    "        else:\n",
    "            p_value_array.append([ticker, start_period.strftime('%Y-%m-%d'), end_period.strftime('%Y-%m-%d'), None])\n",
    "\n",
    "for i in tickers:\n",
    "    print(f\"Test for normality for stock, {i}\")\n",
    "    print('--'*40)\n",
    "    # Filter p_value_array entries for the current ticker i\n",
    "    ticker_entries = [entry for entry in p_value_array if entry[0] == i]\n",
    "    \n",
    "    for entry in ticker_entries:\n",
    "        p_val = entry[3]\n",
    "        start_date = entry[1]\n",
    "        end_date = entry[2]\n",
    "\n",
    "        if p_val < 0.05:\n",
    "            print(f\"No statistically significant evidence for normal distribution for time period: {start_date} to {end_date}\")\n",
    "        else:\n",
    "            print(f\"Statistically significant evidence for normal distribution for time period: {start_date} to {end_date}\")\n",
    "    print('--'*40)\n",
    "    print('--'*40)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a00a6-57d4-4e9b-bbc6-0cb7197dc73e",
   "metadata": {},
   "source": [
    "Thus, we observe that, for the given stocks, while their log-daily returns over the past five years do not exhibit evidence of normality, there is evidence supporting normality over certain one-year intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de78f3f-2901-4b2c-be78-d89e6320bf79",
   "metadata": {},
   "source": [
    "## Testing for Normality after removing extremal data\n",
    "\n",
    "For removing extremal data of previously given stocks, we exclude log-daily returns data points outside the quantile range of 2 and 98 percentile. After trimming, we then test for normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c621df26-cae1-491e-bba5-13069149697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for trimming extremal data in quantile range of 5th and 95th percentile\n",
    "def trim_extremes(data, lower_quantile=0.02, upper_quantile=0.98):\n",
    "    low = np.quantile(data, lower_quantile)\n",
    "    high = np.quantile(data, upper_quantile)\n",
    "    trimmed_data = data[(data >= low) & (data <= high)]\n",
    "    return trimmed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d720f9cb-56e4-4a2f-bb58-05a2938f1399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2499018/2826289210.py:10: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  stock = yf.download(tickers, start = start_date, end =end_date)\n",
      "[*********************100%***********************]  8 of 8 completed\n"
     ]
    }
   ],
   "source": [
    "#downloading stock data\n",
    "\n",
    "# Upload stock x-number of stock data for 2 years\n",
    "tickers= ['AMZN', 'MSFT', 'GOOG', 'HD', 'GM','AAPL', 'INTC', 'ADBE']\n",
    "\n",
    "\n",
    "start_date = dt.datetime.today()-dt.timedelta(days = 5*365)\n",
    "end_date = dt.datetime.today()\n",
    "\n",
    "stock = yf.download(tickers, start = start_date, end =end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ca9eeee-2cfe-40ac-b47a-9a2783cb744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AMZN', 0.3557547963830886], ['MSFT', 0.024520457347429962], ['GOOG', 0.05076975301184344], ['HD', 0.00715072276890955], ['GM', 0.5551199021276989], ['AAPL', 0.028486611303305886], ['INTC', 0.052580037722450214], ['ADBE', 0.0014048113821803732]]\n"
     ]
    }
   ],
   "source": [
    "#Trime data and collect p-values of normality tests (D'Agostino and Pearson’s test)\n",
    "\n",
    "# Initialize list to store p-values\n",
    "p_value_array = []\n",
    "\n",
    "for i in tickers:\n",
    "    # Calculate daily returns and log returns for ticker i\n",
    "    stock_returns = stock['Close'] / stock['Close'].shift(1)\n",
    "    stock_log_returns = np.log(stock_returns.dropna())[i].values\n",
    "\n",
    "    #trim data\n",
    "    trimmed_returns=trim_extremes(stock_log_returns)\n",
    "\n",
    "\n",
    "    # Perform normality test and extract p-value\n",
    "    p_value = stats.normaltest(trimmed_returns)[1]\n",
    "    \n",
    "    # Append ticker and p-value to list\n",
    "    p_value_array.append([i, p_value])\n",
    "\n",
    "# Print p-values for all stocks\n",
    "print(p_value_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b6433ec-128a-4f05-ad68-ca1710c6c06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for normality for stock, AMZN\n",
      "→ No statistically significant evidence against normality.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, MSFT\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, GOOG\n",
      "→ No statistically significant evidence against normality.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, HD\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, GM\n",
      "→ No statistically significant evidence against normality.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, AAPL\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, INTC\n",
      "→ No statistically significant evidence against normality.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Test for normality for stock, ADBE\n",
      "→ Statistically significant evidence that the data is NOT normally distributed.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Print evidence/non-evidence of normality\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    print(f\"Test for normality for stock, {tickers[i]}\")\n",
    "    p_value = p_value_array[i]\n",
    "    if p_value[1]< 0.05:\n",
    "        print(\"→ Statistically significant evidence that the data is NOT normally distributed.\")\n",
    "    else:    \n",
    "       print(\"→ No statistically significant evidence against normality.\")\n",
    "    print('--'*40) \n",
    "    print('--'*40) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b585d879-75bb-48a5-91e7-15b34b891624",
   "metadata": {},
   "source": [
    "Thus, after removing the extremal data, we see evidence of normality of log-daily returns for some of the given stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d88925-00f1-4ef6-9534-918293393f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
